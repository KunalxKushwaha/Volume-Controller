# ğŸ–ğŸ”Š Gesture-Based Volume Controller Using OpenCV & MediaPipe

A computer vision project that transforms your hand gestures into system volume controls â€” no physical interaction required.<br>

While itâ€™s a relatively simple utility, it showcases the power of combining AI, computer vision, and user-centric design. These technologies can lead to more intuitive, accessible, and contactless user experiences â€” something that's increasingly relevant in todayâ€™s tech landscape.<br>

This project helped me strengthen my understanding of:

Real-time data processing

Human-computer interaction

System-level audio control

Modular code design and debugging under performance constraints


<h3>ğŸ¯ Objective</h3>
To build a touchless and user-friendly method of controlling system volume by simply adjusting the space between your fingers â€” promoting a more modern, contactless interaction experience, useful for presentations, media control, or accessibility contexts.

âš™ï¸ Core Technologies<br>
OpenCV: Real-time webcam input and overlay visuals (volume bar, hand annotations).

MediaPipe Hands: Robust hand tracking model that provides 21 landmark points per hand.

Pycaw: Python library to access and control the Windows audio endpoint API.

NumPy + Math: For efficient distance and interpolation calculations.




<h3>ğŸ›  Features</h3><br>
ğŸ‘ï¸ Real-time finger tracking with low latency.

ğŸ”‰ Live volume adjustment based on finger distance.

ğŸ“Š On-screen volume bar and percentage display.

ğŸ–¼ï¸ Smooth graphics with OpenCV.

ğŸ”„ Smoothing logic for stable volume transitions.

âŒ No external hardware or buttons required.

# Author - Kunal Kushwaha
