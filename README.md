# 🖐🔊 Gesture-Based Volume Controller Using OpenCV & MediaPipe

A computer vision project that transforms your hand gestures into system volume controls — no physical interaction required.<br>

While it’s a relatively simple utility, it showcases the power of combining AI, computer vision, and user-centric design. These technologies can lead to more intuitive, accessible, and contactless user experiences — something that's increasingly relevant in today’s tech landscape.<br>

This project helped me strengthen my understanding of:
Real-time data processing

Human-computer interaction

System-level audio control.

Modular code design and debugging under performance constraints.


<h2>🎯 Objective</h2>
To build a touchless and user-friendly method of controlling system volume by simply adjusting the space between your fingers — promoting a more modern, contactless interaction experience, useful for presentations, media control, or accessibility contexts.

<h2>⚙️ Core Technologies<br></h2>
OpenCV: Real-time webcam input and overlay visuals (volume bar, hand annotations).

MediaPipe Hands: Robust hand tracking model that provides 21 landmark points per hand.

Pycaw: Python library to access and control the Windows audio Endpoint API.

NumPy + Math: For efficient distance and interpolation calculations.




<h2>🛠 Features</h2><br>
👁️ Real-time finger tracking with low latency.

🔉 Live volume adjustment based on finger distance.

📊 On-screen volume bar and percentage display.

🖼️ Smooth graphics with OpenCV.

🔄 Smoothing logic for stable volume transitions.

❌ No external hardware or buttons required.

# Author - Kunal Kushwaha✒️
