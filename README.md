# 🖐🔊 Gesture-Based Volume Controller Using OpenCV & MediaPipe

A computer vision project that transforms your hand gestures into system volume controls — no physical interaction required.<br>

While it’s a relatively simple utility, it showcases the power of combining AI, computer vision, and user-centric design. These technologies can lead to more intuitive, accessible, and contactless user experiences — something that's increasingly relevant in today’s tech landscape.<br>

This project helped me strengthen my understanding of:

Real-time data processing

Human-computer interaction

System-level audio control

Modular code design and debugging under performance constraints


<h3>🎯 Objective</h3>
To build a touchless and user-friendly method of controlling system volume by simply adjusting the space between your fingers — promoting a more modern, contactless interaction experience, useful for presentations, media control, or accessibility contexts.

⚙️ Core Technologies<br>
OpenCV: Real-time webcam input and overlay visuals (volume bar, hand annotations).

MediaPipe Hands: Robust hand tracking model that provides 21 landmark points per hand.

Pycaw: Python library to access and control the Windows audio endpoint API.

NumPy + Math: For efficient distance and interpolation calculations.




<h3>🛠 Features</h3><br>
👁️ Real-time finger tracking with low latency.

🔉 Live volume adjustment based on finger distance.

📊 On-screen volume bar and percentage display.

🖼️ Smooth graphics with OpenCV.

🔄 Smoothing logic for stable volume transitions.

❌ No external hardware or buttons required.

# Author - Kunal Kushwaha
